{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pyltr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import dawg\n",
    "from nltk import ngrams\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def get_single_ngram_features(query_input, ngram_dict):\n",
    "    ngram_scores = []\n",
    "\n",
    "    for n in range(1,7):\n",
    "        sixgrams = ngrams(query_input.split(), n)\n",
    "        ngram_score = 0\n",
    "        for grams in sixgrams:\n",
    "            try:\n",
    "                ngram_score = ngram_score + float(ngram_dict[' '.join(grams)])\n",
    "            except:\n",
    "                pass\n",
    "        ngram_scores.append(ngram_score)\n",
    "    return ngram_scores\n",
    "\n",
    "def get_ngram_features(inputs, ngram_dict):\n",
    "    results = [[get_single_ngram_features(x, ngram_dict)] for x in inputs];\n",
    "    return results\n",
    "\n",
    "\n",
    "# Importing all the necessary dictionaries\n",
    "suffixes = pd.read_csv(\"../data/Freq_background.csv\", index_col='Unnamed: 0')\n",
    "with open('../data/sorted_popular_queries.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    skipheader = next(reader)\n",
    "    data=[tuple([line[1], int(line[2])]) for line in reader]\n",
    "sortedpopulardict = dawg.IntCompletionDAWG(data)\n",
    "\n",
    "with open('../data/ngram_dict.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    ngram_dict = {rows[0]:rows[1] for rows in reader}\n",
    "# prefix_suffix_pairs_background = pd.read_csv(\"../data/prefix_suffix_pairs.txt\")\n",
    "\n",
    "data = []\n",
    "\n",
    "top100k = suffixes.iloc[range(100000),:]\n",
    "suffixes = []\n",
    "top100ktuple = [tuple(x) for x in top100k.values]\n",
    "# top100ktuple = [tuple([line[\"0\"], int(line[\"counts\"])])]\n",
    "top100kdict = dawg.IntCompletionDAWG(top100ktuple)\n",
    "top100k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Read in training data\n",
    "removed_session_training = pd.read_csv('../data/removed_session_training.csv', header=None, index_col=[0])\n",
    "removed_session_training[1] = removed_session_training[1].str.replace('[\\W_]+', ' ')\n",
    "\n",
    "training_queries = removed_session_training[:1000].reset_index(drop=True)\n",
    "candidate_prefixes = []\n",
    "right_query = []\n",
    "\n",
    "for j in range(len(training_queries)):\n",
    "    current_query = str(training_queries[1][j])\n",
    "    split_query = current_query.split(\" \")\n",
    "    suffix = ' '.join(split_query[1:])\n",
    "    prefix = split_query[0] + \" \"\n",
    "\n",
    "    for i in range(len(suffix)+1):\n",
    "        candidate_prefixes.append(prefix + suffix[:i])\n",
    "        right_query.append(current_query)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to clear memory\n",
    "all_candidates = []\n",
    "relevant_candidate = []\n",
    "qids =  []\n",
    "ngram_features =  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/11323\n",
      "1000/11323\n",
      "2000/11323\n",
      "3000/11323\n",
      "4000/11323\n",
      "5000/11323\n",
      "6000/11323\n",
      "7000/11323\n",
      "8000/11323\n",
      "9000/11323\n",
      "10000/11323\n",
      "11000/11323\n",
      "Total time: 63.08382844924927\n",
      "Top100k suffix time: 0.44184350967407227\n",
      "Total split time: 0.1052556037902832\n",
      "Total append time: 0.19327688217163086\n",
      "Total ngram time: 4.6560070514678955\n",
      "Total real query time: 57.650792360305786\n"
     ]
    }
   ],
   "source": [
    "all_candidates = []\n",
    "relevant_candidate = []\n",
    "qids =  []\n",
    "ngram_features =  []\n",
    "\n",
    "time_taken_top100k = 0\n",
    "split_time = 0 \n",
    "appendtime = 0\n",
    "ngramtime = 0\n",
    "real_query_time = 0\n",
    "total_time_begin = time.time()\n",
    "\n",
    "for candidate_prefix_i in range(len(candidate_prefixes)):\n",
    "    if candidate_prefix_i % 1000 == 0:\n",
    "        print(str(candidate_prefix_i) + '/' + str(len(candidate_prefixes)))\n",
    "    candidate_prefix = candidate_prefixes[candidate_prefix_i]\n",
    "    original_query = right_query[candidate_prefix_i]\n",
    "    \n",
    "#     Getting the endterm for every prefix\n",
    "    split_time_start = time.time()\n",
    "    splitted = re.split('[\\W_]+',candidate_prefix)\n",
    "    if candidate_prefix[len(candidate_prefix)-1] == ' ':\n",
    "        endterm = splitted[len(splitted)-2] + \" \"\n",
    "    else:\n",
    "        endterm = splitted[len(splitted)-1]\n",
    "    split_time = split_time + time.time() - split_time_start\n",
    "    \n",
    "    # Creating the synthetic candidates\n",
    "    start = time.time()\n",
    "    top10suffix = nlargest(10, top100kdict.items(prefix=candidate_prefix), key=itemgetter(1))\n",
    "    out = [i[0] for i in top10suffix]    \n",
    "    preprefix = candidate_prefix[:-len(endterm)]\n",
    "    outcombined1 = [preprefix + s for s in out]\n",
    "    time_taken_top100k = time_taken_top100k + time.time() - start\n",
    "    \n",
    "    # Getting the top 50 real queries\n",
    "    realquerystart = time.time()\n",
    "    top50queries = nlargest(25, sortedpopulardict.items(prefix=candidate_prefix), key=itemgetter(1))\n",
    "    keys_pop = [i[0] for i in top50queries]\n",
    "    current_candidates = outcombined1\n",
    "    current_candidates.extend(keys_pop)\n",
    "    real_query_time = real_query_time + time.time() - realquerystart\n",
    "    \n",
    "    # Appending\n",
    "    append_time_start = time.time()\n",
    "    all_candidates.extend(current_candidates)    \n",
    "    relevant_candidate.extend([s == original_query for s in current_candidates])\n",
    "    qids.extend(np.ones(len(current_candidates)) * candidate_prefix_i)\n",
    "    appendtime = appendtime + time.time() - append_time_start\n",
    "\n",
    "    # Creating features\n",
    "    ngram_time_start = time.time()\n",
    "    ngram_features = np.append(ngram_features, get_ngram_features(current_candidates, ngram_dict))\n",
    "    ngramtime = ngramtime + time.time() - ngram_time_start\n",
    "    \n",
    "total_time = time.time() - total_time_begin\n",
    "\n",
    "print(\"Total time: \" + str(total_time))\n",
    "print(\"Top100k suffix time: \" + str(time_taken_top100k))\n",
    "print(\"Total split time: \" + str(split_time))\n",
    "print(\"Total append time: \" + str(appendtime))\n",
    "print(\"Total ngram time: \" + str(ngramtime))\n",
    "print(\"Total real query time: \" + str(real_query_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www bankofamerica com',\n",
       " 'www pogo com',\n",
       " 'www irs gov',\n",
       " 'www disneychannel com',\n",
       " 'www disney channel com',\n",
       " 'www ask com',\n",
       " 'www mysapce com',\n",
       " 'www yahoo',\n",
       " 'www my',\n",
       " 'www ebay',\n",
       " 'www mapquest',\n",
       " 'www wellsfargo com',\n",
       " 'www nick com',\n",
       " 'www my space com',\n",
       " 'www walmart com',\n",
       " 'www fafsa gov',\n",
       " 'www askjeeves com',\n",
       " 'www weather com',\n",
       " 'www disney com',\n",
       " 'www cartoonnetwork com',\n",
       " 'www wachovia com',\n",
       " 'www http',\n",
       " 'www target com',\n",
       " 'www google co',\n",
       " 'www craigslist com',\n",
       " 'www cingular com',\n",
       " 'www google cm',\n",
       " 'www myspace cm',\n",
       " 'www macy s com',\n",
       " 'www chase com',\n",
       " 'www blackplanet com',\n",
       " 'www aol com',\n",
       " 'www amazon com',\n",
       " 'www bankofamerica',\n",
       " 'www usps com',\n",
       " 'www match com',\n",
       " 'www southwest com',\n",
       " 'www goo',\n",
       " 'www fafsa ed gov',\n",
       " 'www googl com',\n",
       " 'www www bankofamerica com',\n",
       " 'www www blackplanet com',\n",
       " 'www www bankofamerica',\n",
       " 'www www bet com',\n",
       " 'www www barbie com',\n",
       " 'www www bedbath',\n",
       " 'www www b',\n",
       " 'www www bedbathbeyond com',\n",
       " 'www www bank of america com',\n",
       " 'www www bestbuy com',\n",
       " 'www bankofamerica com',\n",
       " 'www blackplanet com',\n",
       " 'www bankofamerica',\n",
       " 'www bet com',\n",
       " 'www barbie com',\n",
       " 'www bedbath',\n",
       " 'www b',\n",
       " 'www bedbathbeyond com',\n",
       " 'www bestbuy com',\n",
       " 'www barnes',\n",
       " 'www bank of america com',\n",
       " 'www bigboobsalert com',\n",
       " 'www bankone com',\n",
       " 'www bratz com',\n",
       " 'www bellsouth com',\n",
       " 'www babiesrus com',\n",
       " 'www bank of america',\n",
       " 'www bb',\n",
       " 'www bedbathandbeyond com',\n",
       " 'www blockbuster com',\n",
       " 'www blackpeoplemeet com',\n",
       " 'www bbandt com',\n",
       " 'www bankof america com',\n",
       " 'www bebo com',\n",
       " 'www bedbathandbeyond',\n",
       " 'www boostmobile com',\n",
       " 'www betterbusinessbureau com',\n",
       " 'www bet',\n",
       " 'www best buy com',\n",
       " 'www brackenspub com',\n",
       " 'www bearshare com',\n",
       " 'www benefits ml com',\n",
       " 'www blackbarbara com',\n",
       " 'www bellsouth net',\n",
       " 'www bestgirlsofcolombia com',\n",
       " 'www boxerjam com',\n",
       " 'www bigfishgames com',\n",
       " 'www barebacksex com',\n",
       " 'www bigoo com',\n",
       " 'www bankofamerican com',\n",
       " 'www bankofameria com',\n",
       " 'www blair com',\n",
       " 'www bedbathand beyond com',\n",
       " 'www babiesrus',\n",
       " 'www babyphat com',\n",
       " 'www buildabear com',\n",
       " 'www bankofameica com',\n",
       " 'www bj s com',\n",
       " 'www bordersrewards com',\n",
       " 'www bellsouth',\n",
       " 'www www boostmobile com',\n",
       " 'www www boxerjam com',\n",
       " 'www www bordersrewards com',\n",
       " 'www www borders com',\n",
       " 'www www boston com',\n",
       " 'www www bofa com',\n",
       " 'www www bow wow com',\n",
       " 'www www boost mobile com',\n",
       " 'www www bowwow com',\n",
       " 'www www bonus com',\n",
       " 'www boostmobile com',\n",
       " 'www boxerjam com',\n",
       " 'www bordersrewards com',\n",
       " 'www borders com',\n",
       " 'www boston com',\n",
       " 'www bofa com',\n",
       " 'www bonus com',\n",
       " 'www bow wow com',\n",
       " 'www bowwow com',\n",
       " 'www bobsanimalfights com',\n",
       " 'www bodog com',\n",
       " 'www boost mobile com',\n",
       " 'www boattrader com',\n",
       " 'www bombaycompany com dreams',\n",
       " 'www bored com',\n",
       " 'www bookfinder comwww bookfinder com',\n",
       " 'www boscov s com',\n",
       " 'www bowl com',\n",
       " 'www boostmobile com activate',\n",
       " 'www bop gov',\n",
       " 'www boobs com',\n",
       " 'www boostmobile',\n",
       " 'www bostoncollege edu',\n",
       " 'www boysex com',\n",
       " 'www bo',\n",
       " 'www bodybyjake com',\n",
       " 'www bob',\n",
       " 'www bootytalk com',\n",
       " 'www borisonline com',\n",
       " 'www boobzillas com',\n",
       " 'www born4xxx com',\n",
       " 'www bollywoodmusic com',\n",
       " 'www boflex com',\n",
       " 'www boscovs com',\n",
       " 'www bostonglobe com',\n",
       " 'www bobbyjack com',\n",
       " 'www book mark net',\n",
       " 'www bounceeverywhere com',\n",
       " 'www bowflex com',\n",
       " 'www boneme com',\n",
       " 'www booksamillion com',\n",
       " 'www booty com',\n",
       " 'www bose com',\n",
       " 'www bollywoodcity com',\n",
       " 'www books com',\n",
       " 'www bow wow',\n",
       " 'www boats com',\n",
       " 'www bobandtom com',\n",
       " 'www bobevans com survey',\n",
       " 'www bombaycompany com',\n",
       " 'www www bonus com',\n",
       " 'www bonus com',\n",
       " 'www boneme com',\n",
       " 'www bonanza com',\n",
       " 'www bondagewizard com',\n",
       " 'www bonton com',\n",
       " 'www boneyardstan com',\n",
       " 'www bonjovi com',\n",
       " 'www bonnieplants com',\n",
       " 'www bonro com',\n",
       " 'www bonappetit com',\n",
       " 'www bonnaroo com',\n",
       " 'www bonsecours com',\n",
       " 'www bonusgames com',\n",
       " 'www bonds com',\n",
       " 'www bonus',\n",
       " 'www boners com',\n",
       " 'www boni capones com',\n",
       " 'www bonappetite com',\n",
       " 'www bonaventurehotel com',\n",
       " 'www bonazze com',\n",
       " 'www boni capone s com',\n",
       " 'www bonus comhttp',\n",
       " 'www bon anno com',\n",
       " 'www bon jovi com',\n",
       " 'www bonappetit',\n",
       " 'www boncav com',\n",
       " 'www bondagescape com',\n",
       " 'www bonds gov',\n",
       " 'www bondstcollections com',\n",
       " 'www bone thugs n harmony com',\n",
       " 'www bonesbend com',\n",
       " 'www bonespur com',\n",
       " 'www bongojeans com',\n",
       " 'www bonibaru com',\n",
       " 'www bonjovi livedaily com',\n",
       " 'www bonneylakesingle com',\n",
       " 'www bon jovi',\n",
       " 'www bon ton com',\n",
       " 'www bonaedu org',\n",
       " 'www bonandnd com',\n",
       " 'www bonanzabusline com',\n",
       " 'www bonaroo com',\n",
       " 'www bonasera com',\n",
       " 'www bonbon babies',\n",
       " 'www bonbonarie com',\n",
       " 'www boncofamerica com',\n",
       " 'www bondage com',\n",
       " 'www bondagecast com',\n",
       " 'www bondagefriendsusa com',\n",
       " 'www bondageman net',\n",
       " 'www bonsecours com',\n",
       " 'www bonsai com',\n",
       " 'www bonsaikittenscom',\n",
       " 'www bonsaikitty com',\n",
       " 'www bons com',\n",
       " 'www bonsai friends com',\n",
       " 'www bonsai of brooklyn',\n",
       " 'www bonsaicenter com',\n",
       " 'www bonsaiconnection com',\n",
       " 'www bonsaidirectory com',\n",
       " 'www bonsaiempire com',\n",
       " 'www bonsaifriends com',\n",
       " 'www bonsaiinformation comindex html',\n",
       " 'www bonsaiinformation comjap bowl close up small jpgmall jpg',\n",
       " 'www bonsaikitty co',\n",
       " 'www bonsaisupply com',\n",
       " 'www bonsalgallery com or www riverratboatworks com contact info',\n",
       " 'www bonsecorshealthsystems com',\n",
       " 'www bonsecour',\n",
       " 'www bonsecoure org',\n",
       " 'www bonsecourehospital org',\n",
       " 'www bonsecourenroll com',\n",
       " 'www bonsecourhospital',\n",
       " 'www bonsecourhospital org',\n",
       " 'www bonsecours org',\n",
       " 'www bonsecourschippenhamhospital com',\n",
       " 'www bonsecous com sfmc',\n",
       " 'www bonsecur',\n",
       " 'www bonsignorekartshop com',\n",
       " 'www bonsoaboy com',\n",
       " 'www bonspeedcustom wheels com',\n",
       " 'www bonssecourshospitals com',\n",
       " 'www bonsua om',\n",
       " 'www bonsai com',\n",
       " 'www bonsaikittenscom',\n",
       " 'www bonsaikitty com',\n",
       " 'www bonsai friends com',\n",
       " 'www bonsai of brooklyn',\n",
       " 'www bonsaicenter com',\n",
       " 'www bonsaiconnection com',\n",
       " 'www bonsaidirectory com',\n",
       " 'www bonsaiempire com',\n",
       " 'www bonsaifriends com',\n",
       " 'www bonsaiinformation comindex html',\n",
       " 'www bonsaiinformation comjap bowl close up small jpgmall jpg',\n",
       " 'www bonsaikitty co',\n",
       " 'www bonsaisupply com',\n",
       " 'www bonsalgallery com or www riverratboatworks com contact info',\n",
       " 'www bonsai com',\n",
       " 'www bonsaikittenscom',\n",
       " 'www bonsaikitty com',\n",
       " 'www bonsai friends com',\n",
       " 'www bonsai of brooklyn',\n",
       " 'www bonsaicenter com',\n",
       " 'www bonsaiconnection com',\n",
       " 'www bonsaidirectory com',\n",
       " 'www bonsaiempire com',\n",
       " 'www bonsaifriends com',\n",
       " 'www bonsaiinformation comindex html',\n",
       " 'www bonsaiinformation comjap bowl close up small jpgmall jpg',\n",
       " 'www bonsaikitty co',\n",
       " 'www bonsaisupply com',\n",
       " 'www bonsai com',\n",
       " 'www bonsai friends com',\n",
       " 'www bonsai of brooklyn',\n",
       " 'loislaw com',\n",
       " 'loislaw com',\n",
       " 'loislaw com',\n",
       " 'loislaw com',\n",
       " 'www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www bankofamerica com',\n",
       " 'www pogo com',\n",
       " 'www irs gov',\n",
       " 'www disneychannel com',\n",
       " 'www disney channel com',\n",
       " 'www ask com',\n",
       " 'www mysapce com',\n",
       " 'www yahoo',\n",
       " 'www my',\n",
       " 'www ebay',\n",
       " 'www mapquest',\n",
       " 'www wellsfargo com',\n",
       " 'www nick com',\n",
       " 'www my space com',\n",
       " 'www walmart com',\n",
       " 'www fafsa gov',\n",
       " 'www askjeeves com',\n",
       " 'www weather com',\n",
       " 'www disney com',\n",
       " 'www cartoonnetwork com',\n",
       " 'www wachovia com',\n",
       " 'www http',\n",
       " 'www target com',\n",
       " 'www google co',\n",
       " 'www craigslist com',\n",
       " 'www cingular com',\n",
       " 'www google cm',\n",
       " 'www myspace cm',\n",
       " 'www macy s com',\n",
       " 'www chase com',\n",
       " 'www blackplanet com',\n",
       " 'www aol com',\n",
       " 'www amazon com',\n",
       " 'www bankofamerica',\n",
       " 'www usps com',\n",
       " 'www match com',\n",
       " 'www southwest com',\n",
       " 'www goo',\n",
       " 'www fafsa ed gov',\n",
       " 'www googl com',\n",
       " 'www www target com',\n",
       " 'www www travelocity com',\n",
       " 'www www trust4free ws',\n",
       " 'www www ticketmaster com',\n",
       " 'www www the n com',\n",
       " 'www www t mobile com',\n",
       " 'www www tracfone com',\n",
       " 'www www tagged com',\n",
       " 'www www tmobile com',\n",
       " 'www www turbotax com',\n",
       " 'www target com',\n",
       " 'www trust4free ws',\n",
       " 'www travelocity com',\n",
       " 'www ticketmaster com',\n",
       " 'www t mobile com',\n",
       " 'www the n com',\n",
       " 'www tracfone com',\n",
       " 'www tagged com',\n",
       " 'www tmobile com',\n",
       " 'www turbotax com',\n",
       " 'www toyrus com',\n",
       " 'www then com',\n",
       " 'www tatiwbth12345biz',\n",
       " 'www travelocity',\n",
       " 'www twcnyc com',\n",
       " 'www thehun com',\n",
       " 'www toysrus com',\n",
       " 'www tnlottery com',\n",
       " 'www teenflicks com',\n",
       " 'www tsp gov',\n",
       " 'www t',\n",
       " 'www thegap com',\n",
       " 'www trollz com',\n",
       " 'www target',\n",
       " 'www taxact com',\n",
       " 'www toyota com',\n",
       " 'www twistedlinks net',\n",
       " 'www topsecretrecipes com',\n",
       " 'www tmoble com',\n",
       " 'www the',\n",
       " 'www t moble com',\n",
       " 'www txlottery org',\n",
       " 'www tmoblie com',\n",
       " 'www toontown com',\n",
       " 'www t moblie com',\n",
       " 'www trendscounter com',\n",
       " 'www ticketmaster',\n",
       " 'www tribuneindia com',\n",
       " 'www toys r us com',\n",
       " 'www target com survey',\n",
       " 'www thefacebook com',\n",
       " 'www t i com',\n",
       " 'www thankyounetwork com',\n",
       " 'www tsp com',\n",
       " 'www tulane edu',\n",
       " 'www tamatown com',\n",
       " 'www tiffany',\n",
       " 'www thebestse com',\n",
       " 'www true com',\n",
       " 'www t mobile',\n",
       " 'www www target com',\n",
       " 'www www tagged com',\n",
       " 'www www tatiwbth12345biz',\n",
       " 'www www target',\n",
       " 'www www taxact com',\n",
       " 'www www target com survey',\n",
       " 'www www tamatown com',\n",
       " 'www www tax state va us',\n",
       " 'www www tagworld com',\n",
       " 'www www taxcut com',\n",
       " 'www target com',\n",
       " 'www tagged com',\n",
       " 'www tatiwbth12345biz',\n",
       " 'www target',\n",
       " 'www taxact com',\n",
       " 'www target com survey',\n",
       " 'www tamatown com',\n",
       " 'www tax state va us',\n",
       " 'www tagworld com',\n",
       " 'www taxcut com',\n",
       " 'www talbots com',\n",
       " 'www tagged',\n",
       " 'www tax virginia gov',\n",
       " 'www tampabukkake com',\n",
       " 'www tamagotchi com',\n",
       " 'www tasteofhome com',\n",
       " 'www taxact',\n",
       " 'www targetcom',\n",
       " 'www taxactonline com',\n",
       " 'www target co',\n",
       " 'www taca com',\n",
       " 'www ta',\n",
       " 'www tangowire com',\n",
       " 'www tattoos com',\n",
       " 'www taxes state mn us',\n",
       " 'www tag com',\n",
       " 'www target comhttp',\n",
       " 'www tastethemystery com',\n",
       " 'www tax ohio gov',\n",
       " 'www talbots',\n",
       " 'www target om',\n",
       " 'www taxslayer com',\n",
       " 'www talkmatch com',\n",
       " 'www tarot com',\n",
       " 'www taxes hrblock com',\n",
       " 'www tax state wv us',\n",
       " 'www tamagotchitown com',\n",
       " 'www tag',\n",
       " 'www talk com',\n",
       " 'www target cm',\n",
       " 'www tax va gov',\n",
       " 'www talksexwithsue com',\n",
       " 'www tattoo com',\n",
       " 'www tacaairlines com',\n",
       " 'www takeexamsonline com',\n",
       " 'www tax gov',\n",
       " 'www tax ok gov',\n",
       " 'www tamatown',\n",
       " 'www tar',\n",
       " 'www tasty12 com',\n",
       " 'www tabutoys com',\n",
       " 'www taboospeedshop com',\n",
       " 'www tablemate com',\n",
       " 'www taboo com',\n",
       " 'www tabc st tx us',\n",
       " 'www tabitha smith com',\n",
       " 'www tab archive com',\n",
       " 'www tabayoyong com',\n",
       " 'www tabcoupons com',\n",
       " 'www tabcrawler com',\n",
       " 'www tabernacle',\n",
       " 'www tabernacle augusta org',\n",
       " 'www tabernaculo com',\n",
       " 'www tabernaculo org',\n",
       " 'www tabexpress com',\n",
       " 'www tabhall com',\n",
       " 'www tablabs net',\n",
       " 'www tableking com',\n",
       " 'www tablelegs com',\n",
       " 'www tablemountainanimal org',\n",
       " 'www tablemountainanimalcenter com',\n",
       " 'www tabo com au',\n",
       " 'www tabolts',\n",
       " 'www taboo dreams com',\n",
       " 'www taboo top com',\n",
       " 'www taborama com',\n",
       " 'www tabou com',\n",
       " 'www tabslinger com',\n",
       " 'www tabu com',\n",
       " 'www tabula rasa com',\n",
       " 'www tabworld',\n",
       " 'www tabworld com',\n",
       " 'www tabzilla com',\n",
       " 'www tab',\n",
       " 'www tab com',\n",
       " 'www tab org ',\n",
       " 'www tab rv com',\n",
       " 'www tab5jamaica com',\n",
       " 'www tabacaleratropical com',\n",
       " 'www tabacchus com',\n",
       " 'www tabacohut com',\n",
       " 'www tabaddor',\n",
       " 'www tabaddor com',\n",
       " 'www tabaddor comwww tadaddor com',\n",
       " 'www tabadixie cm',\n",
       " 'www tabadixie com',\n",
       " 'www tabagojazzfest com',\n",
       " 'www tabak s com',\n",
       " 'www tabak s health com',\n",
       " 'www tabak s health products com',\n",
       " 'www tabitha smith com',\n",
       " 'www tabi ca',\n",
       " 'www tabinn com',\n",
       " 'www tabit net',\n",
       " 'www tabitha com',\n",
       " 'www tabitha smith msd k12 mo us',\n",
       " 'www tabithafox com',\n",
       " 'www tabithaordan com',\n",
       " 'www tabithastevensondvd com',\n",
       " 'idx cisdata net',\n",
       " 'idx mlspin com',\n",
       " 'idx benefits',\n",
       " 'idx corporation',\n",
       " 'idx file',\n",
       " 'idx file program',\n",
       " 'idx pruchamberlainstien',\n",
       " 'www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www yahoo com',\n",
       " 'www google com',\n",
       " 'www myspace com',\n",
       " 'www ebay com',\n",
       " 'www google',\n",
       " 'www ',\n",
       " 'www hotmail com',\n",
       " 'www mapquest com',\n",
       " 'www myspace',\n",
       " 'www msn com',\n",
       " 'www bankofamerica com',\n",
       " 'www pogo com',\n",
       " 'www irs gov',\n",
       " 'www disneychannel com',\n",
       " 'www disney channel com',\n",
       " 'www ask com',\n",
       " 'www mysapce com',\n",
       " 'www yahoo',\n",
       " 'www my',\n",
       " 'www ebay',\n",
       " 'www mapquest',\n",
       " 'www wellsfargo com',\n",
       " 'www nick com',\n",
       " 'www my space com',\n",
       " 'www walmart com',\n",
       " 'www fafsa gov',\n",
       " 'www askjeeves com',\n",
       " 'www weather com',\n",
       " 'www disney com',\n",
       " 'www cartoonnetwork com',\n",
       " 'www wachovia com',\n",
       " 'www http',\n",
       " 'www target com',\n",
       " 'www google co',\n",
       " 'www craigslist com',\n",
       " 'www cingular com',\n",
       " 'www google cm',\n",
       " 'www myspace cm',\n",
       " 'www macy s com',\n",
       " 'www chase com',\n",
       " 'www blackplanet com',\n",
       " 'www aol com',\n",
       " 'www amazon com',\n",
       " 'www bankofamerica',\n",
       " 'www usps com',\n",
       " 'www match com',\n",
       " 'www southwest com',\n",
       " 'www goo',\n",
       " 'www fafsa ed gov',\n",
       " 'www googl com',\n",
       " 'www www bankofamerica com',\n",
       " 'www www blackplanet com',\n",
       " 'www www bankofamerica',\n",
       " 'www www bet com',\n",
       " 'www www barbie com',\n",
       " 'www www bedbath',\n",
       " 'www www b',\n",
       " 'www www bedbathbeyond com',\n",
       " 'www www bank of america com',\n",
       " 'www www bestbuy com',\n",
       " 'www bankofamerica com',\n",
       " 'www blackplanet com',\n",
       " 'www bankofamerica',\n",
       " 'www bet com',\n",
       " 'www barbie com',\n",
       " 'www bedbath',\n",
       " 'www b',\n",
       " 'www bedbathbeyond com',\n",
       " 'www bestbuy com',\n",
       " 'www barnes',\n",
       " 'www bank of america com',\n",
       " 'www bigboobsalert com',\n",
       " 'www bankone com',\n",
       " 'www bratz com',\n",
       " 'www bellsouth com',\n",
       " 'www babiesrus com',\n",
       " 'www bank of america',\n",
       " 'www bb',\n",
       " 'www bedbathandbeyond com',\n",
       " 'www blockbuster com',\n",
       " 'www blackpeoplemeet com',\n",
       " 'www bbandt com',\n",
       " 'www bankof america com',\n",
       " 'www bebo com',\n",
       " 'www bedbathandbeyond',\n",
       " 'www boostmobile com',\n",
       " 'www betterbusinessbureau com',\n",
       " 'www bet',\n",
       " 'www best buy com',\n",
       " 'www brackenspub com',\n",
       " 'www bearshare com',\n",
       " 'www benefits ml com',\n",
       " 'www blackbarbara com',\n",
       " 'www bellsouth net',\n",
       " 'www bestgirlsofcolombia com',\n",
       " 'www boxerjam com',\n",
       " 'www bigfishgames com',\n",
       " 'www barebacksex com',\n",
       " 'www bigoo com',\n",
       " 'www bankofamerican com',\n",
       " 'www bankofameria com',\n",
       " 'www blair com',\n",
       " 'www bedbathand beyond com',\n",
       " 'www babiesrus',\n",
       " 'www babyphat com',\n",
       " 'www buildabear com',\n",
       " 'www bankofameica com',\n",
       " 'www bj s com',\n",
       " 'www bordersrewards com',\n",
       " 'www bellsouth',\n",
       " 'www www bratz com',\n",
       " 'www www brackenspub com',\n",
       " 'www www bratzpack com',\n",
       " 'www www break com',\n",
       " 'www www branchministry net',\n",
       " 'www www brevardcc edu',\n",
       " 'www www bravotv com',\n",
       " 'www www brylanehomes com',\n",
       " 'www www bratz pack com',\n",
       " 'www www brewers com',\n",
       " 'www bratz com',\n",
       " 'www brackenspub com',\n",
       " 'www bratzpack com',\n",
       " 'www break com',\n",
       " 'www branchministry net',\n",
       " 'www brevardcc edu',\n",
       " 'www brylanehomes com',\n",
       " 'www bravotv com',\n",
       " 'www brewers com',\n",
       " 'www brownco3 com',\n",
       " 'www bradfordexchangechecks com',\n",
       " 'www bratz pack com',\n",
       " 'www bringustoyourtable com',\n",
       " 'www bryngochwelshcobs com',\n",
       " 'www briggs',\n",
       " 'www bratz',\n",
       " 'www brevardclerk us',\n",
       " 'www britishairways com',\n",
       " 'www browardschools com',\n",
       " 'www brylanehome com',\n",
       " 'www brooklynpubliclibrary org',\n",
       " 'www bruce campbell com',\n",
       " 'www bravo com',\n",
       " 'www brockport edu',\n",
       " 'www brother com',\n",
       " 'www brainpop com',\n",
       " 'www bridgetheatrecompany org',\n",
       " 'www broward edu',\n",
       " 'www britney spears sex nude com',\n",
       " 'www bridgettemorgan com',\n",
       " 'www brighton com',\n",
       " 'www brownco com',\n",
       " 'www brownpride com',\n",
       " 'www brylanhome com',\n",
       " 'www br',\n",
       " 'www breatheheavy com',\n",
       " 'www broward org revenue',\n",
       " 'www bracketology com',\n",
       " 'www brat com',\n",
       " 'www breastcancer org',\n",
       " 'www brevard cc fl su',\n",
       " 'www brevardcomplaints com',\n",
       " 'www britney spears com',\n",
       " 'www britneyspears com',\n",
       " 'www brain pop com',\n",
       " 'www bremer com',\n",
       " 'www brats com',\n",
       " 'www brookwoodcabinetry com',\n",
       " 'www briloon org',\n",
       " 'www broderbros co',\n",
       " 'www www bringustoyourtable com',\n",
       " 'www www briggs',\n",
       " 'www www britishairways com',\n",
       " 'www bringustoyourtable com',\n",
       " 'www briggs',\n",
       " 'www britishairways com',\n",
       " 'www bridgetheatrecompany org',\n",
       " 'www britney spears sex nude com',\n",
       " 'www bridgettemorgan com',\n",
       " 'www brighton com',\n",
       " 'www britney spears com',\n",
       " 'www britneyspears com',\n",
       " 'www briloon org',\n",
       " 'www briggsandstratton com',\n",
       " 'www bristolmotorspeedway com',\n",
       " 'www bridgew edu',\n",
       " 'www brighthouse com',\n",
       " 'www bricktownwave com',\n",
       " 'www bristolwest com',\n",
       " 'www britainusa com',\n",
       " 'www britishairways',\n",
       " 'www brittanica com',\n",
       " 'www briannaaustin bigstep com',\n",
       " 'www bridgeclublive com',\n",
       " 'www brigadoon com',\n",
       " 'www brighthousenetwork com',\n",
       " 'www brides com',\n",
       " 'www bridgewater edu',\n",
       " 'www brightondawgs com',\n",
       " 'www brightsurf com',\n",
       " 'www brick fist com',\n",
       " 'www bridalworks com',\n",
       " 'www brighten com',\n",
       " 'www brightroom com',\n",
       " 'www briarblues com',\n",
       " 'www bridalmart com',\n",
       " 'www brinker com',\n",
       " 'www brisnet com',\n",
       " 'www british airlines com',\n",
       " 'www british airways com',\n",
       " 'www britneychile com',\n",
       " 'www brittaolsen com',\n",
       " 'www brickellontheriver',\n",
       " 'www brickhouse betty com',\n",
       " 'www bricktownsoccer com',\n",
       " 'www bridal com',\n",
       " 'www bridal s com',\n",
       " 'www bridalstoresdirectory com',\n",
       " 'www bridge scores com',\n",
       " 'www bridgeport com',\n",
       " 'www bridges com',\n",
       " 'www bridgescore com',\n",
       " 'www bridgescore com judi',\n",
       " 'www bridgetheatrecompany org',\n",
       " 'www bridgettemorgan com',\n",
       " 'www bridgew edu',\n",
       " 'www bridgeclublive com',\n",
       " 'www brides com',\n",
       " 'www bridgewater edu',\n",
       " 'www bridalworks com',\n",
       " 'www bridalmart com',\n",
       " 'www bridal com',\n",
       " 'www bridal s com',\n",
       " 'www bridalstoresdirectory com',\n",
       " 'www bridge scores com',\n",
       " 'www bridgeport com',\n",
       " 'www bridges com',\n",
       " 'www bridgescore com',\n",
       " 'www bridgescore com judi',\n",
       " 'www bridalpeople com',\n",
       " 'www bridesave com',\n",
       " 'www bridge edu',\n",
       " 'www bridgeinchicago com',\n",
       " 'www bridgeiscool com',\n",
       " 'www bridgeport properties com',\n",
       " 'www bridgevillede com',\n",
       " 'www bridgewatercu com',\n",
       " 'www bridlewood farm com',\n",
       " 'www bridal and tuxedo shoppe',\n",
       " 'www bridal gal com',\n",
       " 'www bridalbyvalerie',\n",
       " 'www bridalchannel com',\n",
       " 'www bridalclick com',\n",
       " 'www bridalevent com',\n",
       " 'www bridalonlinestore com',\n",
       " 'www bridaloriginals com',\n",
       " 'www bridals by valerie',\n",
       " 'www bridalsbyyvonne com',\n",
       " 'www bridalshower com',\n",
       " 'www bride ru informer',\n",
       " 'www brideguide com',\n",
       " 'www bridesbysandras com',\n",
       " 'www brideschoiceofwaltham com',\n",
       " 'www bridesmaiddresses com',\n",
       " 'www bridesshirt com',\n",
       " 'www bridewise com',\n",
       " 'www bridgebase com',\n",
       " 'www bridgecap com',\n",
       " 'www bridgeport ct',\n",
       " 'www bridgerun com',\n",
       " 'www bridgescores com',\n",
       " 'www bridgescoresdoubles com',\n",
       " 'www bridgestonegolf com',\n",
       " 'www bridlewood farm com',\n",
       " 'www bridlewoodusa com',\n",
       " 'www bridle and bit com',\n",
       " 'www bridleandbi',\n",
       " 'www bridles com',\n",
       " 'www bridleybeach com',\n",
       " 'www bridlewood farm com',\n",
       " 'www bridlewoodusa com',\n",
       " 'www bridle and bit com',\n",
       " 'www bridleandbi',\n",
       " 'www bridles com',\n",
       " 'www bridleybeach com',\n",
       " 'www bridleandbi',\n",
       " 'www bridleandbi',\n",
       " 'www bridleandbi',\n",
       " 'www bridleandbi',\n",
       " 'www bridleandbi',\n",
       " 'gall bladder',\n",
       " 'gall stones',\n",
       " 'gall bladder surgery',\n",
       " 'gall bladder disease',\n",
       " 'gall bladder symptoms',\n",
       " 'gall bladder',\n",
       " 'gall stones',\n",
       " 'gall bladder disease',\n",
       " 'gall bladder surgery',\n",
       " 'gall bladder symptoms',\n",
       " 'gall bladder problems',\n",
       " 'gall bladder attack',\n",
       " 'gall bladder diet',\n",
       " 'gall bladder attacks',\n",
       " 'gall bladder removal',\n",
       " 'gall bladder pain',\n",
       " 'gall stones and lemon',\n",
       " 'gall 20bladder',\n",
       " 'gall s',\n",
       " 'gall bladder disease symptoms',\n",
       " 'gall blatter',\n",
       " 'gall bladder and a high beliruben reading',\n",
       " 'gall bladder attack symptoms',\n",
       " 'gall bladder body',\n",
       " 'gall bladder breathlessness',\n",
       " 'gall bladder cancer',\n",
       " 'gall bladder emergencies and heroin crystals',\n",
       " 'gall bladder information',\n",
       " 'gall bladder lemon juice',\n",
       " 'gall bladder polyps',\n",
       " 'gall bladder stones',\n",
       " 'gall blader',\n",
       " 'gall blater operation',\n",
       " 'gall router com',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall 20bladder 20stones',\n",
       " 'gall baldder',\n",
       " 'gall bla',\n",
       " 'gall bladdar pain',\n",
       " 'gall bladde removal delay due to heroin',\n",
       " 'gall bladder alternatives for the elderly',\n",
       " 'gall bladder analgesic',\n",
       " 'gall bladder and cancer',\n",
       " 'gall bladder and heroin crystals',\n",
       " 'gall bladder and lemon',\n",
       " 'gall bladder and vomiting',\n",
       " 'gall bladder attack symptons',\n",
       " 'gall bladder attack when to call the doctor',\n",
       " 'gall bladder attacks and pain years after surgery',\n",
       " 'gall bladder bile leak',\n",
       " 'gall bladder body placement',\n",
       " 'gall bladder cancer stomach ache',\n",
       " 'gall bladder cancer symptoms',\n",
       " 'gall bladder cancer symtoms',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall s',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall scom',\n",
       " 'gall stone relief',\n",
       " 'gall stone size',\n",
       " 'gall stone systoms',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall stone relief',\n",
       " 'gall stone size',\n",
       " 'gall stone systoms',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall stone relief',\n",
       " 'gall stone size',\n",
       " 'gall stone systoms',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall stone relief',\n",
       " 'gall stone size',\n",
       " 'gall stone systoms',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall stone surgery',\n",
       " 'gall stone symptoms',\n",
       " 'gall stone relief',\n",
       " 'gall stone size',\n",
       " 'gall stone systoms',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gall gall stones',\n",
       " 'gall stones',\n",
       " 'gall stones and lemon',\n",
       " 'gall stones and foods to eat',\n",
       " 'gall stones and symptoms',\n",
       " 'gall stones and treatment',\n",
       " 'gall stones and weight gain',\n",
       " 'gall stones cause lymph nodes to swell enlarge',\n",
       " 'gallstones symptoms',\n",
       " 'gallstones diet',\n",
       " 'gallstones cause lymph nodes to swell enlarge',\n",
       " 'gallstones celiac disease',\n",
       " 'gallstones in the pancreas',\n",
       " 'gallstones infection infected',\n",
       " 'gallstones infection infected lymph nodes',\n",
       " 'gallstones no symptoms',\n",
       " 'gallstones on ultrasound',\n",
       " 'gallstones photographs',\n",
       " 'gallstones pictures',\n",
       " 'gallstones while pregnant',\n",
       " 'http ',\n",
       " 'http my space com',\n",
       " 'http www yahoo com',\n",
       " 'http disney channel com',\n",
       " 'http www my space com',\n",
       " 'http www disney channel com',\n",
       " 'http www google com',\n",
       " 'http ask jeeves com',\n",
       " 'http yahoo com',\n",
       " 'http a href',\n",
       " 'http ',\n",
       " 'http my space com',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = input(\"Query: \")\n",
    "# original_query = input(\"Original query: \")\n",
    "\n",
    "# search_query = re.sub('[\\W_]+',' ', query)\n",
    "# original_query = re.sub('[\\W_]+',' ', original_query)\n",
    "\n",
    "# startt = time.time()\n",
    "# splitted = re.split('[\\W_]+',search_query)\n",
    "# print(splitted)\n",
    "# if query[len(query)-1] == ' ':\n",
    "#     endterm = splitted[len(splitted)-2] + \" \"\n",
    "# else:\n",
    "#     endterm = splitted[len(splitted)-1]\n",
    "\n",
    "# print(\"Endterm -> '\" + endterm + \"'\")\n",
    "\n",
    "# out = top100k[top100k['0'].str.startswith(endterm)].nlargest(10, 'counts')\n",
    "# out2 = sortedpopular[sortedpopular['0'].str.startswith(search_query)].nlargest(40, 'counts')\n",
    "\n",
    "# outcombined1 = query[:-len(endterm)] + out['0'].astype(str)\n",
    "# time.time() - startt\n",
    "# all_candidates = outcombined1.append(out2.iloc[:,0])\n",
    "# relevant_candidate = (all_candidates == original_query).apply(float)\n",
    "\n",
    "# train_input = pd.DataFrame({\n",
    "#     'query': all_candidates,\n",
    "#     'relevant': relevant_candidate,\n",
    "#     'qid': 1\n",
    "# })\n",
    "  \n",
    "# train_input['ngram_features'] = get_ngram_features(all_candidates, ngram_dict)\n",
    "# print(train_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1200        4.99m                                         \n",
      "    2       0.1235        5.07m                                         \n",
      "    3       0.1388        5.11m                                         \n",
      "    4       0.1458        5.06m                                         \n",
      "    5       0.1504        5.05m                                         \n",
      "    6       0.1511        5.04m                                         \n",
      "    7       0.1511        5.01m                                         \n",
      "    8       0.1517        4.96m                                         \n",
      "    9       0.1549        4.92m                                         \n",
      "   10       0.1551        4.86m                                         \n",
      "   15       0.1575        4.59m                                         \n",
      "   20       0.1596        4.37m                                         \n",
      "   25       0.1656        4.09m                                         \n",
      "   30       0.1665        3.81m                                         \n",
      "   35       0.1673        3.53m                                         \n",
      "   40       0.1677        3.27m                                         \n",
      "   45       0.1690        2.99m                                         \n",
      "   50       0.1697        2.72m                                         \n",
      "   60       0.1743        2.20m                                         \n",
      "   70       0.1778        1.67m                                         \n",
      "   80       0.1792        1.12m                                         \n",
      "   90       0.1805       33.67s                                         \n",
      "  100       0.1828        0.00s                                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyltr.models.lambdamart.LambdaMART at 0x7f715c352390>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = pyltr.metrics.err.ERR(highest_score=1, gain_type='identity')\n",
    "\n",
    "model = pyltr.models.LambdaMART(\n",
    "    metric=metric,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "TX2 = ngram_features.reshape(-1, 6) \n",
    "Ty2 = np.array(relevant_candidate)\n",
    "Tqids2 = np.array(qids)\n",
    "model.fit(TX2, Ty2, Tqids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.txt') as trainfile, \\\n",
    "        open('../data/vali.txt') as valifile, \\\n",
    "        open('../data/test.txt') as evalfile:\n",
    "    TX, Ty, Tqids, _ = pyltr.data.letor.read_dataset(trainfile)\n",
    "    VX, Vy, Vqids, _ = pyltr.data.letor.read_dataset(valifile)\n",
    "    EX, Ey, Eqids, _ = pyltr.data.letor.read_dataset(evalfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "EX = TX2 \n",
    "Ey = Ty2\n",
    "Eqids = Tqids2\n",
    "\n",
    "Epred = model.predict(EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ranking:0.08816215706882063\n",
      "Our model:0.18282111410843654\n"
     ]
    }
   ],
   "source": [
    "metric_MRR = pyltr.metrics.err.ERR(highest_score=1, gain_type='identity')\n",
    "\n",
    "print('Random ranking:' + str(metric_MRR.calc_mean_random(Eqids, Ey)))\n",
    "print('Our model:' + str(metric_MRR.calc_mean(Eqids, Ey, Epred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: False\n",
      "1: False\n",
      "2: False\n",
      "3: False\n",
      "4: False\n",
      "5: False\n",
      "6: False\n",
      "7: False\n",
      "8: False\n",
      "9: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pred_y = pyltr.util.sort.get_sorted_y(Ey, Epred)\n",
    "evaluateMRR(Eqids, sorted_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltr.metrics.err\n",
    "pyltr.metrics.err.ERR.evaluate = evaluate(self, qid, targets):\n",
    "    residual = 1.0\n",
    "    result = 0.0\n",
    "    for i, t in enumerate(targets[:self.k]):\n",
    "        assert t <= self.highest_score\n",
    "        sprob = self._get_satisfied_prob(t)\n",
    "        result += residual * sprob / (1.0 + i)\n",
    "        residual *= (1.0 - sprob)\n",
    "        if residual < _EPS:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87089953 -4.59820971 -3.75258981 -1.29213702 -0.10469242  0.87089953\n",
      " -4.59820971 -3.75258981 -1.29213702 -0.10469242]\n",
      "Random ranking:0.5896918237758785\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e5a87ab72720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Random ranking:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_mean_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEqids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Our model:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEqids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m output = pd.DataFrame({\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyltr-0.2.4-py3.7.egg/pyltr/metrics/_metrics.py\u001b[0m in \u001b[0;36mevaluate_preds\u001b[0;34m(self, qid, targets, preds)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sorted_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_random_ev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyltr-0.2.4-py3.7.egg/pyltr/metrics/dcg.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, qid, targets)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         return (self._dcg.evaluate(qid, targets) /\n\u001b[0;32m---> 74\u001b[0;31m                 max(_EPS, self._get_ideal(qid, targets)))\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_swap_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyltr-0.2.4-py3.7.egg/pyltr/metrics/dcg.py\u001b[0m in \u001b[0;36m_get_ideal\u001b[0;34m(self, qid, targets)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ideal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mideal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ideals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mideal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mideal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "metric = pyltr.metrics.NDCG(gain_type='identity', k=10)\n",
    "print('Our model:' + str(metric.evaluate_preds(Eqids, Ey, Epred)))\n",
    "\n",
    "inputs = ['hello kitty', 'hello my name is jeff', 'hello i am martijn', 'hello who are you', 'hello goodbye', 'hello kitty', 'hello my name is jeff', 'hello i am martijn', 'hello who are you', 'hello goodbye']\n",
    "EX = get_ngram_features(inputs,ngram_dict)\n",
    "EX = np.append([], EX)\n",
    "EX = EX.reshape(-1, 6) \n",
    "Ey = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "Eqids = [0,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "Epred = model.predict(EX)\n",
    "print(Epred)\n",
    "print('Random ranking:' + str(metric.calc_mean_random(Eqids, Ey)))\n",
    "print('Our model:' + str(metric.evaluate_preds(Eqids, Ey, Epred)))\n",
    "output = pd.DataFrame({\n",
    "    'inputs': inputs,\n",
    "    'value': Epred\n",
    "})\n",
    "output.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0.]), array([1., 1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eqids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

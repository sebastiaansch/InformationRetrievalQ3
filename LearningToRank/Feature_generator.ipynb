{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pyltr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import dawg\n",
    "from nltk import ngrams\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "\n",
    "with open('../data/ngram_dict.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "#     ngram_dict = {rows[0]:rows[1] for rows in reader}\n",
    "    ngram_data=[tuple([line[0], int(line[1])]) for line in reader if int(line[1])>2]\n",
    "ngram_dict = dawg.IntCompletionDAWG(ngram_data)\n",
    "# prefix_suffix_pairs_background = pd.read_csv(\"../data/prefix_suffix_pairs.txt\")\n",
    "\n",
    "# Importing all the necessary dictionaries\n",
    "suffixes = pd.read_csv(\"../data/Freq_background.csv\", index_col='Unnamed: 0')\n",
    "with open('../data/sorted_popular_queries.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    skipheader = next(reader)\n",
    "    data=[tuple([line[1], int(line[2])]) for line in reader if int(line[2])>2]\n",
    "sortedpopulardict = dawg.IntCompletionDAWG(data)\n",
    "\n",
    "\n",
    "data = []\n",
    "ngram_data = []\n",
    "\n",
    "## Change this for other top10k, top100k of nothing\n",
    "top100k = suffixes.iloc[range(100000),:]\n",
    "suffixes = []\n",
    "top100ktuple = [tuple(x) for x in top100k.values]\n",
    "# top100ktuple = [tuple([line[\"0\"], int(line[\"counts\"])])]\n",
    "top100kdict = dawg.IntCompletionDAWG(top100ktuple)\n",
    "top100k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_single_ngram_features(query_input, ngram_dict):\n",
    "    ngram_scores = [0,0,0,0,0,0]\n",
    "\n",
    "    for n in range(1,7):\n",
    "        \n",
    "        sixgrams = ngrams(query_input.split(), n)\n",
    "        for grams in sixgrams:\n",
    "            try:\n",
    "                ngram_scores[n-1] = ngram_scores[n-1] + ngram_dict.get(' '.join(grams),0)\n",
    "            except:\n",
    "                pass\n",
    "    return ngram_scores\n",
    "\n",
    "def get_ngram_features(inputs, ngram_dict):\n",
    "    results = [[get_single_ngram_features(x, ngram_dict)] for x in inputs];\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "removed_session_training = pd.read_csv('../data/removed_session_training.csv', header=None, index_col=[0])\n",
    "removed_session_training[1] = removed_session_training[1].str.replace('[\\W_]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process training\n",
    "training_queries = removed_session_training.reset_index(drop=True)\n",
    "candidate_prefixes = []\n",
    "right_query = []\n",
    "\n",
    "amount_of_suffix_splits = 5\n",
    "for j in range(len(training_queries)):\n",
    "    current_query = str(training_queries[1][j])\n",
    "    split_query = current_query.split(\" \")\n",
    "    suffix = ' '.join(split_query[1:])\n",
    "    prefix = split_query[0] + \" \"\n",
    "    \n",
    "    for i in np.unique(np.linspace(0, len(suffix), amount_of_suffix_splits).astype(int)):\n",
    "        candidate_prefixes.append(prefix + suffix[:i])\n",
    "        right_query.append(current_query)\n",
    "    \n",
    "print(\"done\")\n",
    "candidate_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to clear memory\n",
    "all_candidates = []\n",
    "relevant_candidate = []\n",
    "qids =  []\n",
    "ngram_features =  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_candidates = []\n",
    "relevant_candidate = []\n",
    "qids =  []\n",
    "ngram_features =  []\n",
    "\n",
    "time_taken_top100k = 0\n",
    "split_time = 0 \n",
    "appendtime = 0\n",
    "ngramtime = 0\n",
    "real_query_time = 0\n",
    "total_time_begin = time.time()\n",
    "checkpoint_time = time.time()\n",
    "with open('../data/training_feature_data.csv','w') as file:        \n",
    "    for candidate_prefix_i in range(len(candidate_prefixes)):\n",
    "        if candidate_prefix_i % 10000 == 0:\n",
    "            end_checkpoint = time.time() - checkpoint_time\n",
    "            print(\"Time between checkpoints: \" + str(end_checkpoint))\n",
    "            print(\"Total time elapsed: \" + str(time.time() - total_time_begin))\n",
    "            print(str(candidate_prefix_i) + '/' + str(len(candidate_prefixes)))\n",
    "            checkpoint_time = time.time()\n",
    "\n",
    "        candidate_prefix = candidate_prefixes[candidate_prefix_i]\n",
    "        original_query = right_query[candidate_prefix_i]\n",
    "\n",
    "    #     Getting the endterm for every prefix\n",
    "        split_time_start = time.time()\n",
    "        splitted = re.split('[\\W_]+',candidate_prefix)\n",
    "        if candidate_prefix[len(candidate_prefix)-1] == ' ':\n",
    "            endterm = splitted[len(splitted)-2] + \" \"\n",
    "        else:\n",
    "            endterm = splitted[len(splitted)-1]\n",
    "        split_time = split_time + time.time() - split_time_start\n",
    "\n",
    "        # Creating the synthetic candidates\n",
    "        start = time.time()\n",
    "        top10suffix = nlargest(10, top100kdict.items(prefix=candidate_prefix), key=itemgetter(1))\n",
    "        out = [i[0] for i in top10suffix]    \n",
    "        preprefix = candidate_prefix[:-len(endterm)]\n",
    "        outcombined1 = [preprefix + s for s in out]\n",
    "        time_taken_top100k = time_taken_top100k + time.time() - start\n",
    "\n",
    "        current_candidates = outcombined1\n",
    "\n",
    "        # Getting the top # real queries\n",
    "        realquerystart = time.time()\n",
    "        if not(candidate_prefix == \"www \" or candidate_prefix == \"http \"):\n",
    "            top50queries = nlargest(25, sortedpopulardict.items(prefix=candidate_prefix), key=itemgetter(1))\n",
    "            keys_pop = [i[0] for i in top50queries]\n",
    "            current_candidates.extend(keys_pop)\n",
    "        real_query_time = real_query_time + time.time() - realquerystart\n",
    "        \n",
    "        current_relevant_candidates = [s == original_query for s in current_candidates]\n",
    "        \n",
    "        # Appending\n",
    "#         append_time_start = time.time()\n",
    "#         all_candidates.extend(current_candidates)    \n",
    "#         relevant_candidate.extend()\n",
    "#         qids.extend(np.ones(len(current_candidates)) * candidate_prefix_i)\n",
    "#         appendtime = appendtime + time.time() - append_time_start\n",
    "\n",
    "#         # Creating features\n",
    "#         ngram_time_start = time.time()\n",
    "#         ngram_features.extend(get_ngram_features(current_candidates, ngram_dict))\n",
    "#         ngramtime = ngramtime + time.time() - ngram_time_start\n",
    "\n",
    "        feature_vector = get_ngram_features(current_candidates, ngram_dict)\n",
    "        for i in range(len(feature_vector)):\n",
    "            file.write(str(feature_vector[i][0]) + \";\" + str(int(current_relevant_candidates[i])) + \";\" + str(current_candidates[i]) + \";\" + str(candidate_prefix_i))\n",
    "            file.write('\\n')\n",
    "total_time = time.time() - total_time_begin\n",
    "\n",
    "print(\"Total time: \" + str(total_time))\n",
    "print(\"Top100k suffix time: \" + str(time_taken_top100k))\n",
    "print(\"Total split time: \" + str(split_time))\n",
    "print(\"Total append time: \" + str(appendtime))\n",
    "print(\"Total ngram time: \" + str(ngramtime))\n",
    "print(\"Total real query time: \" + str(real_query_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5007075, 120466, 25682, 0, 0, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = input(\"Query: \")\n",
    "# original_query = input(\"Original query: \")\n",
    "\n",
    "# search_query = re.sub('[\\W_]+',' ', query)\n",
    "# original_query = re.sub('[\\W_]+',' ', original_query)\n",
    "\n",
    "# startt = time.time()\n",
    "# splitted = re.split('[\\W_]+',search_query)\n",
    "# print(splitted)\n",
    "# if query[len(query)-1] == ' ':\n",
    "#     endterm = splitted[len(splitted)-2] + \" \"\n",
    "# else:\n",
    "#     endterm = splitted[len(splitted)-1]\n",
    "\n",
    "# print(\"Endterm -> '\" + endterm + \"'\")\n",
    "\n",
    "# out = top100k[top100k['0'].str.startswith(endterm)].nlargest(10, 'counts')\n",
    "# out2 = sortedpopular[sortedpopular['0'].str.startswith(search_query)].nlargest(40, 'counts')\n",
    "\n",
    "# outcombined1 = query[:-len(endterm)] + out['0'].astype(str)\n",
    "# time.time() - startt\n",
    "# all_candidates = outcombined1.append(out2.iloc[:,0])\n",
    "# relevant_candidate = (all_candidates == original_query).apply(float)\n",
    "\n",
    "# train_input = pd.DataFrame({\n",
    "#     'query': all_candidates,\n",
    "#     'relevant': relevant_candidate,\n",
    "#     'qid': 1\n",
    "# })\n",
    "  \n",
    "# train_input['ngram_features'] = get_ngram_features(all_candidates, ngram_dict)\n",
    "# print(train_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pyltr.metrics.err.ERR(highest_score=1, gain_type='identity')\n",
    "\n",
    "model = pyltr.models.LambdaMART(\n",
    "    metric=metric,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "TX2 = ngram_features.reshape(-1, 6) \n",
    "Ty2 = np.array(relevant_candidate)\n",
    "Tqids2 = np.array(qids)\n",
    "model.fit(TX2, Ty2, Tqids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.txt') as trainfile, \\\n",
    "        open('../data/vali.txt') as valifile, \\\n",
    "        open('../data/test.txt') as evalfile:\n",
    "    TX, Ty, Tqids, _ = pyltr.data.letor.read_dataset(trainfile)\n",
    "    VX, Vy, Vqids, _ = pyltr.data.letor.read_dataset(valifile)\n",
    "    EX, Ey, Eqids, _ = pyltr.data.letor.read_dataset(evalfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EX = TX2 \n",
    "Ey = Ty2\n",
    "Eqids = Tqids2\n",
    "\n",
    "Epred = model.predict(EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_MRR = MRR.MRR(highest_score=1, gain_type='identity', k=10)\n",
    "\n",
    "print('Random ranking:' + str(metric_MRR.calc_mean_random(Eqids, Ey)))\n",
    "print('Our model:' + str(metric_MRR.calc_mean(Eqids, Ey, Epred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pred_y = pyltr.util.sort.get_sorted_y(Ey, Epred)\n",
    "evaluateMRR(Eqids, sorted_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltr.metrics.err\n",
    "pyltr.metrics.err.ERR.evaluate = evaluate(self, qid, targets):\n",
    "    residual = 1.0\n",
    "    result = 0.0\n",
    "    for i, t in enumerate(targets[:self.k]):\n",
    "        assert t <= self.highest_score\n",
    "        sprob = self._get_satisfied_prob(t)\n",
    "        result += residual * sprob / (1.0 + i)\n",
    "        residual *= (1.0 - sprob)\n",
    "        if residual < _EPS:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pyltr.metrics.NDCG(gain_type='identity', k=10)\n",
    "print('Our model:' + str(metric.evaluate_preds(Eqids, Ey, Epred)))\n",
    "\n",
    "inputs = ['hello kitty', 'hello my name is jeff', 'hello i am martijn', 'hello who are you', 'hello goodbye', 'hello kitty', 'hello my name is jeff', 'hello i am martijn', 'hello who are you', 'hello goodbye']\n",
    "EX = get_ngram_features(inputs,ngram_dict)\n",
    "EX = np.append([], EX)\n",
    "EX = EX.reshape(-1, 6) \n",
    "Ey = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "Eqids = [0,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "Epred = model.predict(EX)\n",
    "print(Epred)\n",
    "print('Random ranking:' + str(metric.calc_mean_random(Eqids, Ey)))\n",
    "print('Our model:' + str(metric.evaluate_preds(Eqids, Ey, Epred)))\n",
    "output = pd.DataFrame({\n",
    "    'inputs': inputs,\n",
    "    'value': Epred\n",
    "})\n",
    "output.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eqids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

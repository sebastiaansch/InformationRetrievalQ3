{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MRR\n",
    "import csv\n",
    "import time\n",
    "import dawg\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"../data/training_feature_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_lines = 106161931\n",
    "num_validation_lines = 102964961\n",
    "amount_of_divisions = 20\n",
    "\n",
    "preallocate_training = int(num_training_lines / (amount_of_divisions))\n",
    "preallocate_validation = int(num_validation_lines / (amount_of_divisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak klaar voor andere feature krijgen\n",
    "\n",
    "with open('../data/sorted_popular_queries.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    skipheader = next(reader)\n",
    "    data=[tuple([line[1], int(line[2])]) for line in reader if int(line[2])>2]\n",
    "sortedpopulardict = dawg.IntDAWG(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/ 5308096\n",
      "2000000/ 5308096\n",
      "3000000/ 5308096\n"
     ]
    }
   ],
   "source": [
    "# training_data = pd.read_csv(\"../data/training_feature_data.csv\", header=None)\n",
    "\n",
    "start_time = time.time()\n",
    "training_ngram_features = []\n",
    "training_ylabels = []\n",
    "training_qids = []\n",
    "\n",
    "training_ngram_features=preallocate_training*[[0,0,0,0,0,0]]\n",
    "training_ylabels=preallocate_training*[np.bool(0)]\n",
    "training_qids=preallocate_training*[np.int(0)]\n",
    "training_popular_count_feature = preallocate_training*[np.int(0)]\n",
    "training_word_length_feature = preallocate_training*[np.int(0)]\n",
    "training_char_length_feature = preallocate_training*[np.int(0)]\n",
    "training_lastspace_feature=preallocate_training*[np.bool(0)]\n",
    "\n",
    "i = 0\n",
    "with open(training_file, newline='\\n') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    prev_qid = -1\n",
    "    current_qid = -1\n",
    "    split_counter = 0\n",
    "    \n",
    "    for row in spamreader:\n",
    "        if int(row[3]) % amount_of_divisions == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get features\n",
    "        training_ngram_features[i] = eval(row[0])\n",
    "        training_popular_count_feature[i] = sortedpopulardict.get(row[2], 0)\n",
    "        training_word_length_feature[i] = len(row[2].split())\n",
    "        training_char_length_feature[i] = len(row[2])\n",
    "        training_lastspace_feature[i] = row[2][training_char_length_feature[i] - 1] == ' '\n",
    "\n",
    "        # Set question and label\n",
    "        training_ylabels[i] = np.bool(int(row[1]))\n",
    "        training_qids[i] = int(row[3])\n",
    "        i = i + 1\n",
    "        if i == preallocate_training:\n",
    "            break\n",
    "            \n",
    "        if i % 1000000 == 0:\n",
    "            print(str(i) + \"/ \" + str(preallocate_training))\n",
    "        \n",
    "            \n",
    "training_ngram_ints = np.array(training_ngram_features)\n",
    "training_ylabels_ready = np.array(training_ylabels)\n",
    "training_qids_ready = np.array(training_qids)\n",
    "\n",
    "training_ngram_features = []\n",
    "training_ylabels = []\n",
    "training_qids = []\n",
    "\n",
    "print(\"Dit koste: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file = \"../data/validation_feature_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data = pd.read_csv(\"../data/validation_feature_data.csv\", header=None)\n",
    "\n",
    "start_time = time.time()\n",
    "validation_ngram_features = []\n",
    "validation_ylabels = []\n",
    "validation_qids = []\n",
    "\n",
    "validation_ngram_features=preallocate_validation*[[0,0,0,0,0,0]]\n",
    "validation_ylabels=preallocate_validation*[np.bool(0)]\n",
    "validation_qids=preallocate_validation*[np.int(0)]\n",
    "validation_popular_count_feature = preallocate_validation*[np.int(0)]\n",
    "validation_word_length_feature = preallocate_validation*[np.int(0)]\n",
    "validation_char_length_feature = preallocate_validation*[np.int(0)]\n",
    "validation_lastspace_feature=preallocate_validation*[np.bool(0)]\n",
    "\n",
    "i = 0\n",
    "with open(validation_file, newline='\\n') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    prev_qid = -1\n",
    "    current_qid = -1\n",
    "    split_counter = 0\n",
    "    \n",
    "    for row in spamreader:\n",
    "        if int(row[3]) % amount_of_divisions == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get features\n",
    "        validation_ngram_features[i] = eval(row[0])\n",
    "        validation_popular_count_feature[i] = sortedpopulardict.get(row[2], 0)\n",
    "        validation_word_length_feature[i] = len(row[2].split())\n",
    "        validation_char_length_feature[i] = len(row[2])\n",
    "        validation_lastspace_feature[i] = row[2][validation_char_length_feature[i] - 1] == ' '\n",
    "\n",
    "        # Set question and label\n",
    "        validation_ylabels[i] = np.bool(int(row[1]))\n",
    "        validation_qids[i] = int(row[3])\n",
    "        i = i + 1\n",
    "        if i == preallocate_validation:\n",
    "            break\n",
    "        \n",
    "        if i % 1000000 == 0:\n",
    "            print(str(i) + \"/ \" + str(preallocate_validation))\n",
    "            \n",
    "validation_ngram_ints = np.array(validation_ngram_features)\n",
    "validation_ylabels_ready = np.array(validation_ylabels)\n",
    "validation_qids_ready = np.array(validation_qids)\n",
    "\n",
    "validation_ngram_features = []\n",
    "validation_ylabels = []\n",
    "validation_qids = []\n",
    "\n",
    "print(\"Dit koste: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the features, ngram, word length, char length, popularity & last space\n",
    "\n",
    "training_features_final = np.ndarray(shape=(len(training_ngram_ints), 10))\n",
    "for i in range(len(training_ngram_ints)):\n",
    "    training_features_final[i] = np.append(training_ngram_ints[i], [training_popular_count_feature[i], training_word_length_feature[i], training_char_length_feature[i], training_lastspace_feature[i]])\n",
    "\n",
    "del training_ngram_ints\n",
    "del training_popular_count_feature\n",
    "del training_word_length_feature\n",
    "del training_char_length_feature\n",
    "del training_lastspace_feature\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the features, ngram, word length, char length, popularity & last space\n",
    "\n",
    "validation_features_final = np.ndarray(shape=(len(validation_ngram_ints), 10))\n",
    "for i in range(len(validation_ngram_ints)):\n",
    "    validation_features_final[i] = np.append(validation_ngram_ints[i], [validation_popular_count_feature[i], validation_word_length_feature[i], validation_char_length_feature[i], validation_lastspace_feature[i]])\n",
    "\n",
    "del validation_ngram_ints\n",
    "del validation_popular_count_feature\n",
    "del validation_word_length_feature\n",
    "del validation_char_length_feature\n",
    "del validation_lastspace_feature\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pyltr.metrics.ERR(k=10, highest_score = 1)\n",
    "metric_MRR = MRR.MRR(k=10, highest_score = 1)\n",
    "\n",
    "# Only needed if you want to perform validation (early stopping & trimming)\n",
    "monitor = pyltr.models.monitors.ValidationMonitor(\n",
    "    validation_features_final, validation_ylabels_ready, validation_qids_ready, metric=metric, stop_after=5)\n",
    "\n",
    "model = pyltr.models.LambdaMART(\n",
    "    metric=metric,\n",
    "    n_estimators=300,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(training_features_final, training_ylabels_ready, training_qids_ready, monitor=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( model, open( \"model1top100k5iter.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing_data = pd.read_csv(\"../data/testing_feature_data.csv\", header=None)\n",
    "testing_file = \"../data/testing_feature_data.csv\"\n",
    "start_time = time.time()\n",
    "testing_ngram_features = []\n",
    "testing_ylabels = []\n",
    "testing_qids = []\n",
    "preallocate_testing = 26821328\n",
    "testing_ngram_features=preallocate_testing*[[0,0,0,0,0,0]]\n",
    "testing_ylabels=preallocate_testing*[np.bool(0)]\n",
    "testing_qids=preallocate_testing*[np.int(0)]\n",
    "testing_popular_count_feature = preallocate_testing*[np.int(0)]\n",
    "testing_word_length_feature = preallocate_testing*[np.int(0)]\n",
    "testing_char_length_feature = preallocate_testing*[np.int(0)]\n",
    "testing_lastspace_feature=preallocate_testing*[np.bool(0)]\n",
    "\n",
    "i = 0\n",
    "with open(testing_file, newline='\\n') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    prev_qid = -1\n",
    "    current_qid = -1\n",
    "    split_counter = 0\n",
    "    \n",
    "    for row in spamreader:\n",
    "        # Get features\n",
    "        testing_ngram_features[i] = eval(row[0])\n",
    "        testing_popular_count_feature[i] = sortedpopulardict.get(row[2], 0)\n",
    "        testing_word_length_feature[i] = len(row[2].split())\n",
    "        testing_char_length_feature[i] = len(row[2])\n",
    "        testing_lastspace_feature[i] = row[2][testing_char_length_feature[i] - 1] == ' '\n",
    "\n",
    "        # Set question and label\n",
    "        testing_ylabels[i] = np.bool(int(row[1]))\n",
    "        testing_qids[i] = int(row[3])\n",
    "        i = i + 1\n",
    "        \n",
    "            \n",
    "testing_ngram_ints = np.array(testing_ngram_features)\n",
    "testing_ylabels_ready = np.array(testing_ylabels)\n",
    "testing_qids_ready = np.array(testing_qids)\n",
    "\n",
    "testing_ngram_features = []\n",
    "testing_ylabels = []\n",
    "testing_qids = []\n",
    "\n",
    "print(\"Dit koste: \" + str(time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the features, ngram, word length, char length, popularity & last space\n",
    "\n",
    "testing_features_final = np.ndarray(shape=(len(testing_ngram_ints), 10))\n",
    "for i in range(len(testing_ngram_ints)):\n",
    "    testing_features_final[i] = np.append(testing_ngram_ints[i], [testing_popular_count_feature[i], testing_word_length_feature[i], testing_char_length_feature[i], testing_lastspace_feature[i]])\n",
    "\n",
    "del testing_ngram_ints\n",
    "del testing_popular_count_feature\n",
    "del testing_word_length_feature\n",
    "del testing_char_length_feature\n",
    "del testing_lastspace_feature\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epred = model.predict(testing_features_final)\n",
    "print('Our model:' +  str(metric.calc_mean(testing_qids_ready, testing_ylabels_ready, Epred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Our model MRR:'+  str(metric_MRR.calc_mean(testing_qids_ready, testing_ylabels_ready, Epred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bool(int('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
